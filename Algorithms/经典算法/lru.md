# LRU（Least recently used，最近最少使用） 缓存淘汰算法

* 链表实现LRU缓存淘汰策略

维护一个有序的单链表，越靠近链表尾部的节点是越早之前被访问的。当有新的数据被访问的时候，从链表头部开始顺序遍历这个链表。
如果，被访问的数据之前已经被缓存到链表中，遍历得到这个数据相对应的节点，并将其从原来的位置删除，然后插入到链表头部。
当被访问的数据没有存储在缓存的链表中时，并且链表中缓存未满，直接将数据插入链表表头。
当被访问的数据没有存储在缓存的链表中时，并且链表中缓存已满，则删除链表的尾部节点，将新的数据节点插入到链表的头部。

LRU 算法实际上是让你设计数据结构：
首先要接收一个 capacity 参数作为缓存的最大容量，
然后实现两个 API，一个是 put(key, val) 方法存入键值对，另一个是 get(key) 方法获取 key 对应的 val，如果 key 不存在则返回 -1。

## 哈希链表

借助散列表，可以把 LRU 缓存淘汰算法的时间复杂度降低为 O(1)。
双向链表和哈希表的结合体

>思想:借助哈希表赋予了链表快速查找的特性嘛：可以快速查找某个 key 是否存在缓存（链表）中，同时可以快速删除、添加节点。

<img src="../resource/LRU-散列表-双向链表.jpg" width = "600" height = "350"/>
