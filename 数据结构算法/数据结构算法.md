# 数据结构算法

## ![数据结构算法脑图](./resource/数据结构算法脑图.jpg)

## 数据结构算法入门

* 10个基础数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树
* 10个基础算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

## 时间复杂度

  ![时间复杂度公式](./resource/时间复杂度.png)

    大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度

### 时间复杂度量级

 1. 常量阶   O(1)
 1. 对数阶   O(log n)
 1. 线性阶   O(n)
 1. 线性对数阶 O(n logn)
 1. 次方阶   O(n^2), O(n^3),....,O(n^k)
 1. 指数阶   O(2^n)
 1. 阶乘阶   O(n!)

>量级分为: `多项式量级`(常量阶,对数阶,线性阶,线性对数阶,次方阶) `非多项式`(指数阶,阶乘阶)

![复杂度趋势图](./resource/复杂度图.jpg)

### 时间复杂度分析

1. 只关注循环执行次数最多的一段代码

    >大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了,在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了

        例：
        int cal(int n) {
            int sum = 0;
            int i = 1;
            for (; i <= n; ++i) {
                sum = sum + i;
            }
            return sum;
        }

        其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。

2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

    >如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).

        例：
        int cal(int n) {
            int sum_1 = 0;
            int p = 1;
            for (; p < 100; ++p) {
                sum_1 = sum_1 + p;
            }

            int sum_2 = 0;
            int q = 1;
            for (; q < n; ++q) {
                sum_2 = sum_2 + q;
            }

            int sum_3 = 0;
            int i = 1;
            int j = 1;
            for (; i <= n; ++i) {
                j = 1; 
                for (; j <= n; ++j) {
                    sum_3 = sum_3 +  i * j;
                }
            }
            return sum_1 + sum_2 + sum_3;
        }

        第一段代码时间复杂度为常数，在统计时间复杂度趋势时忽略
        第二段时间复杂度为O(n)
        第三段时间复杂度为O(n^2)
        根据加法法则：次代码的时间复杂度为O(n^2)

3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

    >如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).

        例:
        int cal(int n) {
        int ret = 0; 
        int i = 1;
        for (; i < n; ++i) {
            ret = ret + f(i);
        } 
        } 

        int f(int n) {
        int sum = 0;
        int i = 1;
        for (; i < n; ++i) {
            sum = sum + i;
        } 
        return sum;
        }

        cal 函数单独看 时间复杂度为O(n)
        f 函数时间复杂度为O(n)
        整个代码的时间复杂度为T(n) = T1(n) * T2(n) = O(n*n) = O(n^2)

### 常见时间复杂度实例

1. O(1)

    * 一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)

2. O(logn)、O(nlogn)

        例:
        i := 1
        for {
            if i <= n {
                i = i * 2
            }
            break
        }
        时间复杂度即为 `i = i * 2` 的执行次数 2^x = n;x = log2n (2为底),所以时间复杂度为 O(log2n) -> O(logn)

3. O(m+n)、O(m*n)

        例:
        int cal(int m, int n) {
          int sum_1 = 0;
          int i = 1;
          for (; i < m; ++i) {
            sum_1 = sum_1 + i;
          }

          int sum_2 = 0;
          int j = 1;
          for (; j < n; ++j) {
            sum_2 = sum_2 + j;
          }

          return sum_1 + sum_2;
        }

        从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。

        针对这种情况，加法法则就不正确了，需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

### 复杂度分析四个方面

1. 最好情况时间复杂度

    * 最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度

2. 最坏情况时间复杂度

    * 最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度

3. 平均情况时间复杂度

    * 加权平均时间复杂度 期望时间复杂度

4. 均摊时间复杂度

    *

## 空间复杂度

>空间复杂度:`渐进空间复杂度`(asymptotic space complexity)表示`算法的存储空间与数据规模之间的增长关系`。
